{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import te\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 dimension\n",
    "def get_broadcast_abc(shape1, shape2):\n",
    "    # Validation\n",
    "    assert len(shape1) == 2 and len(shape2) == 2 , \"Must to be 2-D\"\n",
    "    for i in range(len(shape1)):\n",
    "        assert shape1[i] == shape2[i] or shape1[i] == 1 or shape2[i] ==1 , \"Broadcast shape error\"\n",
    "    A = te.placeholder(shape1, dtype='float32',name='a')\n",
    "    B = te.placeholder(shape2, dtype='float32',name='b')\n",
    "    m = shape1[0] if shape2[0] == 1 else shape2[0]\n",
    "    n = shape1[1] if shape2[1] == 1 else shape2[1]\n",
    "    f = lambda i,j : A[ 0 if shape1[0] == 1 else i][0 if shape1[1] == 1 else j] + \\\n",
    "    B[0 if shape2[0] ==1 else i][0 if shape2[1] ==1 else j]\n",
    "    C = te.compute((m,n), f, name='c')\n",
    "    return A, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = [te.var(name) for name in ('m', 'n')]\n",
    "shape1 = (m, 1)\n",
    "shape2 = (m, n)\n",
    "A, B, C = get_broadcast_abc(shape1, shape2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IRModuleNode( {GlobalVar(main): PrimFunc([a, b, c]) attrs={\"global_symbol\": \"main\", \"tir.noalias\": (bool)1} {\n",
       "  for (i, 0, m) {\n",
       "    for (j, 0, n) {\n",
       "      c[((i*stride) + (j*stride))] = (a[(i*stride)] + b[((i*stride) + (j*stride))])\n",
       "    }\n",
       "  }\n",
       "}\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = te.create_schedule(C.op)\n",
    "tvm.lower(s, [A,B,C], simple_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tvm.nd.NDArray shape=(3, 1), cpu(0)>\n",
       " array([[0.],\n",
       "        [1.],\n",
       "        [2.]], dtype=float32),\n",
       " <tvm.nd.NDArray shape=(1, 4), cpu(0)>\n",
       " array([[0., 1., 2., 3.]], dtype=float32),\n",
       " <tvm.nd.NDArray shape=(3, 4), cpu(0)>\n",
       " array([[0., 1., 2., 3.],\n",
       "        [1., 2., 3., 4.],\n",
       "        [2., 3., 4., 5.]], dtype=float32))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tvm.nd.array(np.arange(3, dtype='float32').reshape(3,1))\n",
    "b = tvm.nd.array(np.arange(4, dtype='float32').reshape((1,4)))\n",
    "c = tvm.nd.array(np.empty((3,4), dtype='float32'))\n",
    "mod = tvm.build(s, [A, B, C])\n",
    "mod(a, b, c)\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvm_matrix_multi():\n",
    "    m, n, l = [te.var(name) for name in ('m','n','l')]\n",
    "    A = te.placeholder((m, l), dtype='float32', name='a')\n",
    "    B = te.placeholder((l, n), dtype='float32', name='b')\n",
    "    k = te.reduce_axis((0,l), name='k')\n",
    "    f = lambda i, j : te.sum(A[i,k]*B[k,j], axis=k)\n",
    "    C = te.compute((m,n), f, name='c')\n",
    "    return A, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = tvm_matrix_multi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = te.create_schedule(C.op)\n",
    "mod = tvm.build(s, [A,B,C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to the d2ltvm package.\n",
    "def get_abc(shape, constructor=None):\n",
    "    \"\"\"Return random a, b and empty c with the same shape.\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    a = np.random.normal(size=shape).astype(np.float32)\n",
    "    b = np.random.normal(size=shape).astype(np.float32)\n",
    "    c = np.empty_like(a)\n",
    "    if constructor:\n",
    "        a, b, c = [constructor(x) for x in (a, b, c)]\n",
    "    return a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tvm.nd.NDArray shape=(2, 2), cpu(0)>\n",
       " array([[1.7640524, 0.4001572],\n",
       "        [0.978738 , 2.2408931]], dtype=float32),\n",
       " <tvm.nd.NDArray shape=(2, 2), cpu(0)>\n",
       " array([[ 1.867558  , -0.9772779 ],\n",
       "        [ 0.95008844, -0.1513572 ]], dtype=float32),\n",
       " <tvm.nd.NDArray shape=(2, 2), cpu(0)>\n",
       " array([[1.7640524, 0.4001572],\n",
       "        [0.978738 , 2.2408931]], dtype=float32))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b, c = get_abc((2,2), tvm.nd.array)\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tvm.nd.NDArray shape=(2, 2), cpu(0)>\n",
       " array([[1.7640524, 0.4001572],\n",
       "        [0.978738 , 2.2408931]], dtype=float32),\n",
       " <tvm.nd.NDArray shape=(2, 2), cpu(0)>\n",
       " array([[ 1.867558  , -0.9772779 ],\n",
       "        [ 0.95008844, -0.1513572 ]], dtype=float32),\n",
       " <tvm.nd.NDArray shape=(2, 2), cpu(0)>\n",
       " array([[ 3.6746547, -1.784536 ],\n",
       "        [ 3.9568968, -1.2956743]], dtype=float32))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod(a, b, c)\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution\n",
    "## padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(X, ph, pw, val=0):\n",
    "    assert len(X.shape) >= 2 , \"shape error\"\n",
    "    nh, nw = X.shape[-2], X.shape[-1]\n",
    "    return te.compute((*X.shape[0:-2], nh+2*ph, nw+2*pw), lambda *i: te.if_then_else(te.any(i[-2]<ph, i[-1]<pw, i[-2]>=nh+ph, i[-1]>=nw+pw), val, X[i[:-2]+(i[-2]-ph, i[-1]-pw)]), name='pd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tvm.nd.NDArray shape=(3, 4), cpu(0)>\n",
       " array([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]], dtype=float32),\n",
       " <tvm.nd.NDArray shape=(5, 4), cpu(0)>\n",
       " array([[0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = te.placeholder((3,4), name='a')\n",
    "B = padding(A, 1, 0)\n",
    "s = te.create_schedule(B.op)\n",
    "mod = tvm.build(s, [A, B])\n",
    "a = tvm.nd.array(np.ones((3,4), dtype='float32'))\n",
    "b = tvm.nd.array(np.empty((3+2, 4),dtype='float32'))\n",
    "mod(a, b)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to the d2ltvm package.\n",
    "def conv_out_size(n, k, p, s):\n",
    "    \"\"\"Compute the output size by given input size n (width or height),\n",
    "    kernel size k, padding p, and stride s\n",
    "    Return output size (width or height)\n",
    "    \"\"\"\n",
    "    return (n - k + 2 * p)//s + 1\n",
    "\n",
    "# Save to the d2ltvm package.\n",
    "def conv(oc, ic, nh, nw, kh, kw, ph=0, pw=0, sh=1, sw=1):\n",
    "    \"\"\"Convolution\n",
    "\n",
    "    oc, ic : output and input channels\n",
    "    nh, nw : input width and height\n",
    "    kh, kw : kernel width and height\n",
    "    ph, pw : height and width padding sizes, default 0\n",
    "    sh, sw : height and width strides, default 1\n",
    "    \"\"\"\n",
    "    # reduction axes\n",
    "    ric = te.reduce_axis((0, ic), name='ric')\n",
    "    rkh = te.reduce_axis((0, kh), name='rkh')\n",
    "    rkw = te.reduce_axis((0, kw), name='rkw')\n",
    "    # output height and weights\n",
    "    oh = conv_out_size(nh, kh, ph, sh)\n",
    "    ow = conv_out_size(nw, kw, pw, sw)\n",
    "    # pad X and then compute Y\n",
    "    X = te.placeholder((ic, nh, nw), name='X')\n",
    "    K = te.placeholder((oc, ic, kh, kw), name='K')\n",
    "    PaddedX = padding(X, ph, pw) if ph != 0 or pw != 0 else X\n",
    "    Y = te.compute(\n",
    "        (oc, oh, ow),\n",
    "        lambda c, i, j: te.sum(\n",
    "            PaddedX[ric, i*sh+rkh, j*sw+rkw] * K[c, ric, rkh, rkw],\n",
    "            axis=[ric, rkh, rkw]), name='Y')\n",
    "    return X, K, Y, PaddedX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_data(oc, ic, n, k, p=0, s=1, constructor=None):\n",
    "    \"\"\"Return random 3-D data tensor, 3-D kernel tenor and empty 3-D output\n",
    "    tensor with the shapes specified by input arguments.\n",
    "\n",
    "    oc, ic : output and input channels\n",
    "    n : input width and height\n",
    "    k : kernel width and height\n",
    "    p : padding size, default 0\n",
    "    s : stride, default 1\n",
    "    constructor : user-defined tensor constructor\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    data = np.random.normal(size=(ic, n, n)).astype('float32')\n",
    "    weight = np.random.normal(size=(oc, ic, k, k)).astype('float32')\n",
    "    on = conv_out_size(n, k, p, s)\n",
    "    out = np.empty((oc, on, on), dtype='float32')\n",
    "    if constructor:\n",
    "        data, weight, out = (constructor(x) for x in [data, weight, out])\n",
    "    return data, weight, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primfn(X_1: handle, K_1: handle, Y_1: handle) -> ()\n",
      "  attr = {\"global_symbol\": \"main\", \"tir.noalias\": True}\n",
      "  buffers = {Y: Buffer(Y_2: Pointer(float32), float32, [4, 12, 12], []),\n",
      "             K: Buffer(K_2: Pointer(float32), float32, [4, 6, 3, 3], []),\n",
      "             X: Buffer(X_2: Pointer(float32), float32, [6, 12, 12], [])}\n",
      "  buffer_map = {X_1: X, K_1: K, Y_1: Y} {\n",
      "  attr [pd: Pointer(float32)] \"storage_scope\" = \"global\";\n",
      "  allocate(pd, float32, [1176]) {\n",
      "    for (i0: int32, 0, 6) {\n",
      "      for (i1: int32, 0, 14) {\n",
      "        for (i2: int32, 0, 14) {\n",
      "          pd[(((i0*196) + (i1*14)) + i2)] = @tir.if_then_else(((((i1 < 1) || (i2 < 1)) || (13 <= i1)) || (13 <= i2)), 0f32, (float32*)X_2[((((i0*144) + (i1*12)) + i2) - 13)], dtype=float32)\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    for (c: int32, 0, 4) {\n",
      "      for (i: int32, 0, 12) {\n",
      "        for (j: int32, 0, 12) {\n",
      "          Y_2[(((c*144) + (i*12)) + j)] = 0f32\n",
      "          for (ric: int32, 0, 6) {\n",
      "            for (rkh: int32, 0, 3) {\n",
      "              for (rkw: int32, 0, 3) {\n",
      "                Y_2[(((c*144) + (i*12)) + j)] = ((float32*)Y_2[(((c*144) + (i*12)) + j)] + ((float32*)pd[(((((ric*196) + (i*14)) + (rkh*14)) + j) + rkw)]*(float32*)K_2[((((c*54) + (ric*9)) + (rkh*3)) + rkw)]))\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "oc, ic, n, k, p, s = 4, 6, 12, 3, 1, 1\n",
    "X, K, Y, _ = conv(oc, ic, n, n, k, k, p, p, s, s)\n",
    "sch = te.create_schedule(Y.op)\n",
    "mod = tvm.build(sch, [X, K, Y])\n",
    "print(tvm.lower(sch, [X, K, Y], simple_mode=True))\n",
    "\n",
    "data, weight, out = get_conv_data(oc, ic, n, k, p, s, tvm.nd.array)\n",
    "mod(data, weight, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "def get_conv_data_mxnet(oc, ic, n, k, p, s, ctx='cpu'):\n",
    "    ctx = getattr(mx, ctx)()\n",
    "    data, weight, out = get_conv_data(oc, ic, n, k, p, s,\n",
    "                                      lambda x: mx.nd.array(x, ctx=ctx))\n",
    "    data, out = data.expand_dims(axis=0), out.expand_dims(axis=0)\n",
    "    bias = mx.nd.zeros(out.shape[1], ctx=ctx)\n",
    "    return data, weight, bias, out\n",
    "\n",
    "# Save to the d2ltvm package.\n",
    "def conv_mxnet(data, weight, bias, out, k, p, s):\n",
    "    mx.nd.Convolution(data, weight, bias, kernel=(k,k), stride=(s,s),\n",
    "                      pad=(p,p), num_filter=out.shape[1], out=out)\n",
    "\n",
    "data, weight, bias, out_mx = get_conv_data_mxnet(oc, ic, n, k, p, s)\n",
    "conv_mxnet(data, weight, bias, out_mx, k, p, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(out_mx[0].asnumpy(), out.asnumpy(), atol=1e-5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

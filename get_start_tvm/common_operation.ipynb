{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import te\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 dimension\n",
    "def get_broadcast_abc(shape1, shape2):\n",
    "    # Validation\n",
    "    assert len(shape1) == 2 and len(shape2) == 2 , \"Must to be 2-D\"\n",
    "    for i in range(len(shape1)):\n",
    "        assert shape1[i] == shape2[i] or shape1[i] == 1 or shape2[i] ==1 , \"Broadcast shape error\"\n",
    "    A = te.placeholder(shape1, dtype='float32',name='a')\n",
    "    B = te.placeholder(shape2, dtype='float32',name='b')\n",
    "    m = shape1[0] if shape2[0] == 1 else shape2[0]\n",
    "    n = shape1[1] if shape2[1] == 1 else shape2[1]\n",
    "    f = lambda i,j : A[ 0 if shape1[0] == 1 else i][0 if shape1[1] == 1 else j] + \\\n",
    "    B[0 if shape2[0] ==1 else i][0 if shape2[1] ==1 else j]\n",
    "    C = te.compute((m,n), f, name='c')\n",
    "    return A, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = [te.var(name) for name in ('m', 'n')]\n",
    "shape1 = (m, 1)\n",
    "shape2 = (m, n)\n",
    "A, B, C = get_broadcast_abc(shape1, shape2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IRModuleNode( {GlobalVar(main): PrimFunc([a, b, c]) attrs={\"global_symbol\": \"main\", \"tir.noalias\": (bool)1} {\n",
       "  for (i, 0, m) {\n",
       "    for (j, 0, n) {\n",
       "      c[((i*stride) + (j*stride))] = (a[(i*stride)] + b[((i*stride) + (j*stride))])\n",
       "    }\n",
       "  }\n",
       "}\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = te.create_schedule(C.op)\n",
    "tvm.lower(s, [A,B,C], simple_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TVMError",
     "evalue": "Traceback (most recent call last):\n  [bt] (2) /home/lei/tvm/build/libtvm.so(TVMFuncCall+0x63) [0x7f3c077e5763]\n  [bt] (1) /home/lei/tvm/build/libtvm.so(+0x1243821) [0x7f3c077f5821]\n  [bt] (0) /home/lei/tvm/build/libtvm.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x80) [0x7f3c06c28310]\n  File \"/home/lei/tvm/src/runtime/library_module.cc\", line 78\nTVMError: Check failed: ret == 0 (-1 vs. 0) : Assert fail: (m == int32(arg1.shape[0])), Argument arg1.shape[0] has an unsatisfied constraint",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTVMError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-607370edf226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tvm/python/tvm/runtime/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    108\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_entry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentry_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tvm/python/tvm/_ffi/_ctypes/packed_func.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtcodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 ctypes.byref(ret_val), ctypes.byref(ret_tcode)) != 0:\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mget_last_ffi_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTVMError\u001b[0m: Traceback (most recent call last):\n  [bt] (2) /home/lei/tvm/build/libtvm.so(TVMFuncCall+0x63) [0x7f3c077e5763]\n  [bt] (1) /home/lei/tvm/build/libtvm.so(+0x1243821) [0x7f3c077f5821]\n  [bt] (0) /home/lei/tvm/build/libtvm.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x80) [0x7f3c06c28310]\n  File \"/home/lei/tvm/src/runtime/library_module.cc\", line 78\nTVMError: Check failed: ret == 0 (-1 vs. 0) : Assert fail: (m == int32(arg1.shape[0])), Argument arg1.shape[0] has an unsatisfied constraint"
     ]
    }
   ],
   "source": [
    "a = tvm.nd.array(np.arange(3, dtype='float32').reshape(3,1))\n",
    "b = tvm.nd.array(np.arange(4, dtype='float32').reshape((1,4)))\n",
    "c = tvm.nd.array(np.empty((3,4), dtype='float32'))\n",
    "mod = tvm.build(s, [A, B, C])\n",
    "mod(a, b, c)\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvm_matrix_multi():\n",
    "    m, n, l = [te.var(name) for name in ('m','n','l')]\n",
    "    A = te.placeholder((m, l), dtype='float32', name='a')\n",
    "    B = te.placeholder((l, n), dtype='float32', name='b')\n",
    "    k = te.reduce_axis((0,l), name='k')\n",
    "    f = lambda i, j : te.sum(A[i,k]*B[k,j], axis=k)\n",
    "    C = te.compute((m,n), f, name='c')\n",
    "    return A, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C = tvm_matrix_multi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = te.create_schedule(C.op)\n",
    "mod = tvm.build(s, [A,B,C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to the d2ltvm package.\n",
    "def get_abc(shape, constructor=None):\n",
    "    \"\"\"Return random a, b and empty c with the same shape.\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    a = np.random.normal(size=shape).astype(np.float32)\n",
    "    b = np.random.normal(size=shape).astype(np.float32)\n",
    "    c = np.empty_like(a)\n",
    "    if constructor:\n",
    "        a, b, c = [constructor(x) for x in (a, b, c)]\n",
    "    return a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = get_abc((2,2), tvm.nd.array)\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod(a, b, c)\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolution\n",
    "## padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(X, ph, pw, val=0):\n",
    "    assert len(X.shape) >= 2 , \"shape error\"\n",
    "    nh, nw = X.shape[-2], X.shape[-1]\n",
    "    return te.compute((*X.shape[0:-2], nh+2*ph, nw+2*pw), lambda *i: te.if_then_else(te.any(i[-2]<ph, i[-1]<pw, i[-2]>=nh+ph, i[-1]>=nw+pw), val, X[i[:-2]+(i[-2]-ph, i[-1]-pw)]), name='pd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = te.placeholder((3,4), name='a')\n",
    "B = padding(A, 1, 0)\n",
    "s = te.create_schedule(B.op)\n",
    "mod = tvm.build(s, [A, B])\n",
    "a = tvm.nd.array(np.ones((3,4), dtype='float32'))\n",
    "b = tvm.nd.array(np.empty((3+2, 4),dtype='float32'))\n",
    "mod(a, b)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to the d2ltvm package.\n",
    "def conv_out_size(n, k, p, s):\n",
    "    \"\"\"Compute the output size by given input size n (width or height),\n",
    "    kernel size k, padding p, and stride s\n",
    "    Return output size (width or height)\n",
    "    \"\"\"\n",
    "    return (n - k + 2 * p)//s + 1\n",
    "\n",
    "# Save to the d2ltvm package.\n",
    "def conv(oc, ic, nh, nw, kh, kw, ph=0, pw=0, sh=1, sw=1):\n",
    "    \"\"\"Convolution\n",
    "\n",
    "    oc, ic : output and input channels\n",
    "    nh, nw : input width and height\n",
    "    kh, kw : kernel width and height\n",
    "    ph, pw : height and width padding sizes, default 0\n",
    "    sh, sw : height and width strides, default 1\n",
    "    \"\"\"\n",
    "    # reduction axes\n",
    "    ric = te.reduce_axis((0, ic), name='ric')\n",
    "    rkh = te.reduce_axis((0, kh), name='rkh')\n",
    "    rkw = te.reduce_axis((0, kw), name='rkw')\n",
    "    # output height and weights\n",
    "    oh = conv_out_size(nh, kh, ph, sh)\n",
    "    ow = conv_out_size(nw, kw, pw, sw)\n",
    "    # pad X and then compute Y\n",
    "    X = te.placeholder((ic, nh, nw), name='X')\n",
    "    K = te.placeholder((oc, ic, kh, kw), name='K')\n",
    "    PaddedX = padding(X, ph, pw) if ph != 0 or pw != 0 else X\n",
    "    Y = te.compute(\n",
    "        (oc, oh, ow),\n",
    "        lambda c, i, j: te.sum(\n",
    "            PaddedX[ric, i*sh+rkh, j*sw+rkw] * K[c, ric, rkh, rkw],\n",
    "            axis=[ric, rkh, rkw]), name='Y')\n",
    "    return X, K, Y, PaddedX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_data(oc, ic, n, k, p=0, s=1, constructor=None):\n",
    "    \"\"\"Return random 3-D data tensor, 3-D kernel tenor and empty 3-D output\n",
    "    tensor with the shapes specified by input arguments.\n",
    "\n",
    "    oc, ic : output and input channels\n",
    "    n : input width and height\n",
    "    k : kernel width and height\n",
    "    p : padding size, default 0\n",
    "    s : stride, default 1\n",
    "    constructor : user-defined tensor constructor\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    data = np.random.normal(size=(ic, n, n)).astype('float32')\n",
    "    weight = np.random.normal(size=(oc, ic, k, k)).astype('float32')\n",
    "    on = conv_out_size(n, k, p, s)\n",
    "    out = np.empty((oc, on, on), dtype='float32')\n",
    "    if constructor:\n",
    "        data, weight, out = (constructor(x) for x in [data, weight, out])\n",
    "    return data, weight, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oc, ic, n, k, p, s = 4, 6, 12, 3, 1, 1\n",
    "X, K, Y, _ = conv(oc, ic, n, n, k, k, p, p, s, s)\n",
    "sch = te.create_schedule(Y.op)\n",
    "mod = tvm.build(sch, [X, K, Y])\n",
    "print(tvm.lower(sch, [X, K, Y], simple_mode=True))\n",
    "\n",
    "data, weight, out = get_conv_data(oc, ic, n, k, p, s, tvm.nd.array)\n",
    "mod(data, weight, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "def get_conv_data_mxnet(oc, ic, n, k, p, s, ctx='cpu'):\n",
    "    ctx = getattr(mx, ctx)()\n",
    "    data, weight, out = get_conv_data(oc, ic, n, k, p, s,\n",
    "                                      lambda x: mx.nd.array(x, ctx=ctx))\n",
    "    data, out = data.expand_dims(axis=0), out.expand_dims(axis=0)\n",
    "    bias = mx.nd.zeros(out.shape[1], ctx=ctx)\n",
    "    return data, weight, bias, out\n",
    "\n",
    "# Save to the d2ltvm package.\n",
    "def conv_mxnet(data, weight, bias, out, k, p, s):\n",
    "    mx.nd.Convolution(data, weight, bias, kernel=(k,k), stride=(s,s),\n",
    "                      pad=(p,p), num_filter=out.shape[1], out=out)\n",
    "\n",
    "data, weight, bias, out_mx = get_conv_data_mxnet(oc, ic, n, k, p, s)\n",
    "conv_mxnet(data, weight, bias, out_mx, k, p, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(out_mx[0].asnumpy(), out.asnumpy(), atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depthwise Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to the d2ltvm package.\n",
    "def get_conv_data(oc, ic, n, k, p=0, s=1, constructor=None, conv_type='direct'):\n",
    "    \"\"\"Return random 3-D data tensor, 3-D kernel tenor and empty 3-D output\n",
    "    tensor with the shapes specified by input arguments.\n",
    "\n",
    "    oc, ic : output and input channels\n",
    "    n : input width and height\n",
    "    k : kernel width and height\n",
    "    p : padding size, default 0\n",
    "    s : stride, default 1\n",
    "    conv_type: either direct 2D or depthwise, default direct\n",
    "    constructor : user-defined tensor constructor\n",
    "    \"\"\"\n",
    "    np.random.seed(0)\n",
    "    data = np.random.normal(size=(ic, n, n)).astype('float32')\n",
    "    ic_weight = ic\n",
    "    if conv_type == 'depthwise':\n",
    "        ic_weight = 1\n",
    "    weight = np.random.normal(size=(oc, ic_weight, k, k)).astype('float32')\n",
    "    on = d2ltvm.conv_out_size(n, k, p, s)\n",
    "    out = np.empty((oc, on, on), dtype='float32')\n",
    "    if constructor:\n",
    "        data, weight, out = (constructor(x) for x in [data, weight, out])\n",
    "    return data, weight, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to the d2ltvm package.\n",
    "def depthwise_conv(ic, nh, nw, kh, kw, ph=0, pw=0, sh=1, sw=1):\n",
    "    \"\"\"Convolution\n",
    "\n",
    "    ic : number of channels for both input and output\n",
    "    nh, nw : input width and height\n",
    "    kh, kw : kernel width and height\n",
    "    ph, pw : height and width padding sizes, default 0\n",
    "    sh, sw : height and width strides, default 1\n",
    "    \"\"\"\n",
    "    # reduction axes\n",
    "    rkh = te.reduce_axis((0, kh), name='rkh')\n",
    "    rkw = te.reduce_axis((0, kw), name='rkw')\n",
    "    # output height and weights\n",
    "    oh = conv_out_size(nh, kh, ph, sh)\n",
    "    ow = conv_out_size(nw, kw, pw, sw)\n",
    "    # pad X and then compute Y\n",
    "    X = te.placeholder((ic, nh, nw), name='X')\n",
    "    K = te.placeholder((ic, 1, kh, kw), name='K')\n",
    "    PaddedX = padding(X, ph, pw) if ph * pw != 0 else X\n",
    "    Y = te.compute(\n",
    "        (ic, oh, ow),\n",
    "        lambda c, i, j: te.sum(\n",
    "            (PaddedX[c, i*sh+rkh, j*sw+rkw] * K[c, 0, rkh, rkw]),\n",
    "            axis=[rkh, rkw]), name='Y')\n",
    "\n",
    "    return X, K, Y, PaddedX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
